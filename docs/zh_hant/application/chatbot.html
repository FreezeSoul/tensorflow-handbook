

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tensorflow Seq2Seq 閒聊機器人（Huan） &mdash; 简单粗暴 TensorFlow 2 0.4 beta 文档</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../_static/js/tw_cn.js"></script>
        <script type="text/javascript" src="../../_static/js/pangu.min.js"></script>
        <script type="text/javascript" src="../../_static/js/custom_20200921.js"></script>
        <script type="text/javascript" src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> 简单粗暴 TensorFlow 2
          

          
          </a>

          
            
            
              <div class="version">
                0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/foreword.html">推荐序</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/preface.html">前言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/introduction.html">TensorFlow概述</a></li>
</ul>
<p class="caption"><span class="caption-text">基础</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/basic/installation.html">TensorFlow安装与环境配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/basic/basic.html">TensorFlow基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/basic/models.html">TensorFlow 模型建立与训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/basic/tools.html">TensorFlow常用模块</a></li>
</ul>
<p class="caption"><span class="caption-text">部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/deployment/export.html">TensorFlow模型导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/deployment/serving.html">TensorFlow Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/deployment/lite.html">TensorFlow Lite（Jinpeng）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/deployment/javascript.html">TensorFlow in JavaScript（Huan）</a></li>
</ul>
<p class="caption"><span class="caption-text">大规模训练与加速</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/distributed.html">TensorFlow分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/tpu.html">使用TPU训练TensorFlow模型（Huan）</a></li>
</ul>
<p class="caption"><span class="caption-text">扩展</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/tfhub.html">TensorFlow Hub 模型复用（Jinpeng）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/tfds.html">TensorFlow Datasets 数据集载入</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/swift.html">Swift for TensorFlow (S4TF) (Huan）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/quantum.html">TensorFlow Quantum: 混合量子-经典机器学习 *</a></li>
</ul>
<p class="caption"><span class="caption-text">附录</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/rl.html">强化学习简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/docker.html">使用Docker部署TensorFlow环境</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/cloud.html">在云端使用TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/jupyterlab.html">部署自己的交互式Python开发环境JupyterLab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/recommended_books.html">参考资料与推荐阅读</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zh_hans/appendix/terms.html">术语中英对照表</a></li>
</ul>
<p class="caption"><span class="caption-text">目錄</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../preface.html">前言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">TensorFlow概述</a></li>
</ul>
<p class="caption"><span class="caption-text">基礎</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../basic/installation.html">TensorFlow 安裝與環境配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/basic.html">TensorFlow 基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/models.html">TensorFlow 模型建立與訓練</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/tools.html">TensorFlow常用模組</a></li>
</ul>
<p class="caption"><span class="caption-text">部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/export.html">TensorFlow模型匯出</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/serving.html">TensorFlow Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/lite.html">TensorFlow Lite（Jinpeng）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/javascript.html">TensorFlow in JavaScript（Huan）</a></li>
</ul>
<p class="caption"><span class="caption-text">大規模訓練與加速</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix/distributed.html">TensorFlow分布式訓練</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/tpu.html">使用TPU訓練TensorFlow模型（Huan）</a></li>
</ul>
<p class="caption"><span class="caption-text">擴展</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix/tfhub.html">TensorFlow Hub 模型複用（Jinpeng）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/tfds.html">TensorFlow Datasets 資料集載入</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/swift.html">Swift for TensorFlow (S4TF) (Huan）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/quantum.html">TensorFlow Quantum: 混合量子-經典機器學習 *</a></li>
</ul>
<p class="caption"><span class="caption-text">附錄</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix/rl.html">強化學習簡介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/docker.html">使用Docker部署TensorFlow環境</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/cloud.html">在雲端使用TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/jupyterlab.html">部署自己的互動式 Python 開發環境 JupyterLab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/recommended_books.html">參考資料與推薦閱讀</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/terms.html">專有名詞中英對照表</a></li>
</ul>
<p class="caption"><span class="caption-text">Preface</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../en/preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../en/introduction.html">TensorFlow Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../en/basic/installation.html">Installation and Environment Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../en/basic/basic.html">TensorFlow Basic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../en/basic/models.html">Model Construction and Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../en/basic/tools.html">Common Modules in TensorFlow</a></li>
</ul>
<p class="caption"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../en/deployment/export.html">TensorFlow Model Export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../en/deployment/serving.html">TensorFlow Serving</a></li>
</ul>
<p class="caption"><span class="caption-text">Large-scale Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../en/appendix/distributed.html">Distributed training with TensorFlow</a></li>
</ul>
<p class="caption"><span class="caption-text">Extensions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../en/appendix/tfds.html">TensorFlow Datasets: Ready-to-use Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../en/appendix/quantum.html">TensorFlow Quantum: Hybrid Quantum-classical Machine Learning *</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">简单粗暴 TensorFlow 2</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Tensorflow Seq2Seq 閒聊機器人（Huan）</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/zh_hant/application/chatbot.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tensorflow-seq2seq-huan">
<h1>Tensorflow Seq2Seq 閒聊機器人（Huan）<a class="headerlink" href="#tensorflow-seq2seq-huan" title="永久链接至标题">¶</a></h1>
<div class="section" id="tensorflow-python">
<h2>Tensorflow Python 閒聊機器人<a class="headerlink" href="#tensorflow-python" title="永久链接至标题">¶</a></h2>
<p>在本章，我們實現一個可以用來閒聊的對話模型。這個對話模型將基於序列到序列（Seq2Seq）來對電影台詞中的對話資料進行訓練。</p>
<p>序列到序列模型（Sequence to Sequence, SEQ2SEQ）是一種基於 RNN 的 Encoder-Decoder 結構，它也是現在谷歌應用於線上機器翻譯的演算法，翻譯質量已經和人類水平不相上下。</p>
<p>這里通過 Keras 自定義模型建立一個閒聊對話模型（Seq2Seq）。它使用 Encoder-Decoder 結構，簡單的來說就是演算法包含兩部分，一個負責對輸入的信息進行 Encoding，將輸入轉換為向量形式；然後由 Decoder 對這個向量進行解碼，還原為輸出序列。</p>
<p>關於 Seq2Seq 的原理和介紹，可以參考 Keras 的博客：A ten-minute introduction to sequence-to-sequence learning in Keras。地址： <a class="reference external" href="https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html">https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html</a></p>
<p>這里，我們使用 Seq2Seq 來實現一個閒聊（ChitChat）對話機器人。除了閒聊任務（輸入一句話，輸出一句回復）之外，它也可以被直接應用於解決其他類似問題，比如：翻譯（輸入一句英文，輸出一句中文）、摘要（輸入一篇文章，輸出一份總結）、作詩（輸入幾個關鍵字，輸出一首短詩）、對對聯（輸入上聯，輸出下聯），等等。</p>
<p>這個任務對比與之前的RNN尼採風格文本生成，區別在於我們預測的不再是文本的連續字母機率分佈，而是通過一個序列，來預測另外一個對應的完整序列。舉例來說，針對一句常見的打招呼:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">How</span> <span class="n">are</span> <span class="n">you</span>
</pre></div>
</div>
<p>這個句子（序列）一共有3個單詞。當我們聽到這個由3個單詞組成的句子後，根據我們的習慣，我們最傾向與回復的一句話是 “Fine thank you”。我們希望建立這樣的模型，輸入 num_batch 個由編碼後單詞和字元組成的，長為 max_length 的序列，輸入張量形狀為 [num_batch, max_length]，輸出與這個序列對應的序列（如聊天回復、翻譯等）中單詞和字元的機率分佈，機率分佈的維度為詞匯表大小 voc_size，輸出張量形狀為 [num_batch, max_length, voc_size]。</p>
<p>首先，還是實現一個簡單的 <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> 類來讀取文本，</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DATASET_URL</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/huan/python-concise-chitchat/releases/download/v0.0.1/dataset.txt.gz&#39;</span>
<span class="n">DATASET_FILE_NAME</span> <span class="o">=</span> <span class="s1">&#39;concise-chitchat-dataset.txt.gz&#39;</span>
<span class="n">START_TOKEN</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span>
<span class="n">END_TOKEN</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>

<span class="k">class</span> <span class="nc">DataLoader</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">dataset_file</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="n">DATASET_FILE_NAME</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="n">DATASET_URL</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">dataset_file</span><span class="p">,</span> <span class="s1">&#39;rt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">raw_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queries</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parse_raw_text</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_text</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queries</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queries</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">batch_queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queries</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>
        <span class="n">batch_responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">responses</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">batch_queries</span><span class="p">,</span> <span class="n">batch_responses</span>

    <span class="k">def</span> <span class="nf">__parse_raw_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">query_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">response_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">raw_text</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
            <span class="n">query</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">query_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
            <span class="n">response_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;{} {} {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">START_TOKEN</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">END_TOKEN</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">query_list</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">response_list</span><span class="p">)</span>
</pre></div>
</div>
<p>其次，我們還需要基於 <cite>DataLoader</cite> 加載的文本資料，建立一個詞匯表 <cite>Vocabulary</cite> 來負責管理以下5項任務：</p>
<ol class="arabic simple">
<li><p>將所有單詞和標點符號進行編碼；</p></li>
<li><p>記錄詞匯表大小；</p></li>
<li><p>建立單詞到編碼數字，以及編碼數字到單詞的映射字典；</p></li>
<li><p>負責將文本句子轉化為填充後的編碼序列，形狀為[batch_size, max_length]；</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">class</span> <span class="nc">Vocabulary</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">([</span><span class="n">END_TOKEN</span><span class="p">,</span> <span class="n">START_TOKEN</span><span class="p">]</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[\n\s\t]&#39;</span><span class="p">,</span><span class="n">text</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">texts_to_padded_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_list</span><span class="p">):</span>
        <span class="n">sequence_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">text_list</span><span class="p">)</span>
        <span class="n">padded_sequences</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span>
            <span class="n">sequence_list</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span><span class="n">truncating</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">padded_sequences</span>
</pre></div>
</div>
<p>接下來進行模型的實現。我們建立一個ChitChat模型。ChitChat 模型是一個 Seq2Seq 的模型，主要由 ChitEncoder 和 ChatDecoder 組成。</p>
<p>ChitEncoder 子模型輸入 num_batch 個由編碼後單詞和字元組成的，長為 max_length 的序列，輸入張量形狀為 [num_batch, max_length]，輸出與這個序列對應的上下文張量。為了簡化代碼，我們這里只使用一個最基本的 GRU 單元，沒有使用可以獲得更佳效果的雙向RNN、註意力機制等方法。在 <cite>__init__</cite> 方法中我們實例化一個常用的 <cite>GRU</cite> 單元，並將其設置為 <cite>return_state=True</cite> 來獲得最終的狀態輸出，我們首先對序列進行 GRU 操作，即將編碼序列變換為 GRU 最終輸出的狀態 ，並將其作為代表編碼序列的上下文信息 <cite>context</cite> ，作為模型的輸出。</p>
<p><cite>ChitEncoder</cite> 子模型具體實現如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">RNN_UNIT_NUM</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">512</span>

<span class="k">class</span> <span class="nc">ChitEncoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">RNN_UNIT_NUM</span><span class="p">,</span>
            <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="p">[</span><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>ChatDecoder 子模型輸入 num_batch 個編碼後的一個單詞或字元的 Embedding，和當前的上下文信息張量 <cite>initial_state</cite> 兩個信息構成，輸入張量形狀分別為 [num_batch, 1, EMBEDDING_DIM]，和 [num_batch, RNN_UNIT_NUM]。在 <cite>__init__</cite> 方法中我們保存詞匯表容量 <cite>voc_size</cite> ，實例化一個常用的 <cite>GRU</cite> 單元，並將其設置為輸出單元狀態 <cite>return_state=True</cite> 來獲得 GRU 的狀態輸出，以及一個全連接層 <cite>Dense</cite> 單元，負責將 GRU 的輸出變換為最終的單詞字元分佈機率，並將其作為這個上下文信息對應的單詞符號序列機率分佈張量，作為模型的輸出，形狀為[num_batch, 1, voc_size]。</p>
<p><cite>ChitDecoder</cite> 子模型具體實現如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ChatDecoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">voc_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span> <span class="o">=</span> <span class="n">voc_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">RNN_UNIT_NUM</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">):</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="p">[</span><span class="n">initial_state</span><span class="p">])</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>構建 ChitChat 模型將基於上面的兩個 ChitEncoder 和 ChatDecoder 子模型。在 <cite>__init__</cite> 方法中我們將 <cite>Vocabulary</cite> 中的詞匯到編碼字典 <cite>word_index</cite> 和編碼到詞匯字典 <cite>index_word</cite> ，以及詞匯量 <cite>voc_size</cite> 保存備用，實例化一個詞向量的 <cite>Embedding</cite> 單元，以及一個 <cite>ChitEncoder</cite> 子模型和對應的 <cite>ChatDecoder</cite> 子模型。<cite>ChatDecoder</cite> 子模型中需要使用詞匯表尺寸，我們通過構造參數傳給它。</p>
<p>模型的工作流程為：我們首先對輸入序列通過 <cite>Embedding</cite> 層進行詞向量轉換，然後進行 Encoder 操作，即將編碼序列 <cite>inputs</cite> 的詞嵌入向量，變換為一個上下文向量 <cite>encoder_hidden_state</cite> 。然後，我們進入解碼流程：將 START_TOKEN 詞向量和 <cite>encoder_hidden_state</cite> 作為解碼器的首次輸入，解碼得到解碼器的輸出編碼張量 <cite>decoder_outputs</cite>，以及狀態張量 <cite>decoder_state</cite>。接下來將 <cite>decoder_outputs</cite> 和 <cite>decoder_state</cite> 重復輸入解碼器，即可不斷得到新的 <cite>decoder_outputs</cite> 即作為模型的輸出，直到 <cite>decoder_outputs</cite> 解碼出來的字元為 END_TOKEN 為止。最終輸出的張量形狀為[num_batch, max_length, voc_size]。</p>
<p><cite>ChitChat</cite> 模型具體實現如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ChitChat</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_word</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">index_word</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">indice_sos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">START_TOKEN</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indice_eos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">END_TOKEN</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">EMBEDDING_DIM</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">ChitEncoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">ChatDecoder</span><span class="p">(</span><span class="n">voc_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">teacher_forcing_targets</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">batch_sos_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> \
            <span class="o">*</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indice_sos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span><span class="p">)]</span>

        <span class="n">decoder_output</span> <span class="o">=</span> <span class="n">batch_sos_one_hot</span>
        <span class="n">decoder_state</span> <span class="o">=</span> <span class="n">encoder_hidden_state</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">voc_size</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_LEN</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="n">teacher_forcing_targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">target_indice</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                    <span class="n">teacher_forcing_targets</span><span class="p">[:,</span> <span class="n">t</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_indice</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">target_indice</span><span class="p">)</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">decoder_inputs</span><span class="p">,</span>
                <span class="n">initial_state</span><span class="o">=</span><span class="n">decoder_state</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">outputs</span><span class="p">,</span> <span class="n">decoder_output</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</div>
<p>訓練過程與本書的 RNN 模型訓練基本一致，在此復述：</p>
<ul class="simple">
<li><p>從DataLoader中隨機取一批訓練資料；</p></li>
<li><p>將這批資料送入模型，計算出模型的預測值；</p></li>
<li><p>將模型預測值與真實值進行比較，計算損失函數（loss）；</p></li>
<li><p>計算損失函數關於模型變量的導數；</p></li>
<li><p>使用優化器更新模型參數以最小化損失函數。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">NUM_STEP</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">teacher_forcing_targets</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y_without_sos</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">BATCH_SIZE</span><span class="p">],</span> <span class="mf">0.</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">y_without_sos</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_value</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>

<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">chitchat</span> <span class="o">=</span> <span class="n">ChitChat</span><span class="p">(</span><span class="n">vocabulary</span><span class="o">=</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">chitchat</span><span class="p">)</span>

<span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_STEP</span><span class="p">):</span>
    <span class="n">queries</span><span class="p">,</span> <span class="n">responses</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

    <span class="n">queries_sequences</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">texts_to_padded_sequences</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
    <span class="n">responses_sequences</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">texts_to_padded_sequences</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>

    <span class="n">grads</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">chitchat</span><span class="p">,</span> <span class="n">queries_sequences</span><span class="p">,</span> <span class="n">responses_sequences</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads_and_vars</span><span class="o">=</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">chitchat</span><span class="o">.</span><span class="n">variables</span><span class="p">))</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;step </span><span class="si">%d</span><span class="s2">: loss </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch_index</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">(</span><span class="n">chitchat</span><span class="p">,</span> <span class="n">queries_sequences</span><span class="p">,</span> <span class="n">responses_sequences</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="n">checkpoint</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./checkpoints&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>訓練時，可以透過輸出了解模型的loss:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">step</span> <span class="mi">0</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">2.019347</span>
<span class="n">step</span> <span class="mi">10</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.798050</span>
<span class="n">step</span> <span class="mi">20</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.87050</span>
<span class="n">step</span> <span class="mi">30</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.758132</span>
<span class="n">step</span> <span class="mi">40</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.821826</span>
</pre></div>
</div>
<p>模型訓練完成後，我們通過 <cite>checkpoint.save()</cite> 函數將模型的參數存在 <cite>./checkpoints</cite> 目錄中。最後，我們需要一個用來對話的程式，來測試實際效果。我們來給 ChitChat 增加 predict 方法：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ChitChat</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="c1"># ... append the following code to previous code</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">response_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_LEN</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="n">indice</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">indice</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">indice_eos</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">response_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">indice</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response_indices</span>
</pre></div>
</div>
<p>然後，我們就可以實現一個簡單的 Chat 程式。具體實現如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">raw_text</span><span class="p">)</span>

<span class="n">chitchat</span> <span class="o">=</span> <span class="n">ChitChat</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">chitchat</span><span class="p">)</span>
<span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">&#39;./checkpoints&#39;</span><span class="p">))</span>

<span class="n">index_word</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">index_word</span>
<span class="n">word_index</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">query</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;&gt; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">query</span> <span class="o">==</span> <span class="s1">&#39;q&#39;</span> <span class="ow">or</span> <span class="n">query</span> <span class="o">==</span> <span class="s1">&#39;quit&#39;</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

        <span class="n">query_sequence</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">texts_to_padded_sequences</span><span class="p">([</span><span class="n">query</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">response_sequence</span> <span class="o">=</span> <span class="n">chitchat</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">query_sequence</span><span class="p">)</span>

        <span class="n">response_word_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">index_word</span><span class="p">[</span><span class="n">indice</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">indice</span> <span class="ow">in</span> <span class="n">response_sequence</span>
            <span class="k">if</span> <span class="n">indice</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">indice</span> <span class="o">!=</span> <span class="n">word_index</span><span class="p">[</span><span class="n">END_TOKEN</span><span class="p">]</span>
        <span class="p">]</span>

        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Bot:&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response_word_list</span><span class="p">))</span>

    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;OOV: Please use simple words with the ChitChat Bot!&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>最終生成的對話的界面將會是這樣子的:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt; how are you ?
Bot: fine .
&gt; where are you ?
Bot: i don t know .
</pre></div>
</div>
</div>
<div class="section" id="tensorflow-javascript">
<h2>Tensorflow JavaScript 閒聊對話模型<a class="headerlink" href="#tensorflow-javascript" title="永久链接至标题">¶</a></h2>
<p>本章我們將根據前述章節的 Python 版閒聊對話模型，實現一個基於 JavaScript 版的序列到序列模型（Sequence to Sequence, Seq2Seq）。它同樣是基於 RNN 的 Encoder-Decoder 結構，具體基本介紹，請讀者參考 Python 版閒聊對話模型的相關章節。</p>
<p>這里的Encoder-Decoder結構，簡單的來說就是演算法包含兩部分，一個負責對輸入的信息進行Encoding，將輸入轉換為向量形式；然後由Decoder對這個向量進行解碼，還原為輸出序列。</p>
<p>這個任務預測的是通過一個序列，來預測另外一個對應的序列。舉例來說，常見的打招呼就是一個序列到序列的過程:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>輸入：How are you ?
輸出：Fine, thank you .
</pre></div>
</div>
<p>這個過程的輸入序列有4個 token： <code class="docutils literal notranslate"><span class="pre">['how',</span> <span class="pre">'are',</span> <span class="pre">'you',</span> <span class="pre">'?']</span></code> ，輸出序列有5個 token： <code class="docutils literal notranslate"><span class="pre">['fine',</span> <span class="pre">',',</span> <span class="pre">'thank',</span> <span class="pre">'you',</span> <span class="pre">'.']</span></code> 。我們希望建立這樣的模型，輸入長為 <code class="docutils literal notranslate"><span class="pre">maxLength</span></code> 的序列，輸入變數形狀為 <code class="docutils literal notranslate"><span class="pre">[null,</span> <span class="pre">max_length]</span></code> ，輸出與這個序列對應的序列中 token 的機率分佈，機率分佈的維度為詞匯表大小 <code class="docutils literal notranslate"><span class="pre">vocSize</span></code> ，輸出變數形狀為 <code class="docutils literal notranslate"><span class="pre">[null,</span> <span class="pre">maxLength,</span> <span class="pre">vocSize]</span></code> 。</p>
<p>首先，我們下載預先準備好資料集，將其存為 <code class="docutils literal notranslate"><span class="pre">dataset.txt</span></code> 。資料集的格式為每行為一對序列，分別為輸入序列和輸出序列，之間用 <code class="docutils literal notranslate"><span class="pre">'\t'</span></code> 製表符隔開。序列中的每一個 token 之間，都透過 <code class="docutils literal notranslate"><span class="pre">'</span> <span class="pre">'</span></code> 空格符號進行分割。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ wget https://github.com/huan/python-concise-chitchat/releases/download/v0.0.1/dataset.txt.gz
dataset.txt.gz 100% [======================&gt;] 986.60K   282KB/s    in 3.5s

2019-03-15 22:59:00 (282 KB/s) - ‘dataset.txt.gz’ saved [1010276/1010276]

$ gzip -d dataset.txt.gz

$ ls -l dataset.txt
l-rw-r--r--  1 zixia  wheel  3516695 Mar 14 13:15 dataset.txt

$ head -3 dataset.txt
did you change your hair ?  no .
no .        you might wanna think about it
you the new guy ?   so they tell me ...
</pre></div>
</div>
<p>我們需要將它轉換為 Tensorflow Dataset 格式：</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">import</span> <span class="o">*</span> <span class="nx">as</span> <span class="nx">tf</span> <span class="nx">from</span> <span class="s1">&#39;@tensorflow/tfjs&#39;</span>

<span class="nx">type</span> <span class="nx">Seq2seqData</span> <span class="o">=</span> <span class="p">{</span>
  <span class="nx">input</span><span class="o">:</span> <span class="nx">string</span><span class="p">,</span>
  <span class="nx">output</span><span class="o">:</span> <span class="nx">string</span><span class="p">,</span>
<span class="p">}</span>

<span class="kr">const</span> <span class="nx">dataset</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">data</span><span class="p">.</span><span class="nx">csv</span><span class="p">(</span><span class="s1">&#39;dataset.txt&#39;</span><span class="p">,</span> <span class="p">{</span>
    <span class="nx">hasHeader</span><span class="o">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nx">columnNames</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">],</span>
    <span class="nx">delimiter</span><span class="o">:</span> <span class="s1">&#39;\t&#39;</span><span class="p">,</span>
<span class="p">})</span> <span class="nx">as</span> <span class="nx">any</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">data</span><span class="p">.</span><span class="nx">Dataset</span><span class="o">&lt;</span><span class="nx">Seq2seqData</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>其次，我們還需要基於 <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> 中輸入序列和輸出序列中的文本資料，建立對應的詞匯表 <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> 來負責管理以下5項任務：</p>
<ol class="arabic simple">
<li><p>將所有單詞和標點符號進行編碼；</p></li>
<li><p>記錄詞匯表大小；</p></li>
<li><p>建立單詞到編碼數字，以及編碼數字到單詞的對應字典；</p></li>
</ol>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">class</span> <span class="nx">Vocabulary</span> <span class="p">{</span>
  <span class="kr">private</span> <span class="nx">readonly</span> <span class="nx">tokenIndice</span><span class="o">:</span> <span class="nx">Map</span><span class="o">&lt;</span><span class="nx">string</span><span class="p">,</span> <span class="nx">number</span><span class="o">&gt;</span>
  <span class="kr">private</span> <span class="nx">readonly</span> <span class="nx">indiceToken</span><span class="o">:</span> <span class="nx">Map</span><span class="o">&lt;</span><span class="nx">number</span><span class="p">,</span> <span class="nx">string</span><span class="o">&gt;</span>

  <span class="kr">public</span> <span class="nx">maxSeqLength</span><span class="o">:</span> <span class="nx">number</span>
  <span class="kr">public</span> <span class="nx">size</span><span class="o">:</span> <span class="nx">number</span>

  <span class="nx">constructor</span> <span class="p">()</span> <span class="p">{</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">tokenIndice</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Map</span><span class="o">&lt;</span><span class="nx">string</span><span class="p">,</span> <span class="nx">number</span><span class="o">&gt;</span><span class="p">()</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">indiceToken</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Map</span><span class="o">&lt;</span><span class="nx">number</span><span class="p">,</span> <span class="nx">string</span><span class="o">&gt;</span><span class="p">()</span>

    <span class="k">this</span><span class="p">.</span><span class="nx">size</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1">// Including the reserved 0</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">maxSeqLength</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="p">}</span>

  <span class="kr">public</span> <span class="nx">fitToken</span><span class="p">(</span><span class="nx">token</span><span class="o">:</span> <span class="nx">string</span><span class="p">)</span><span class="o">:</span> <span class="k">void</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="k">this</span><span class="p">.</span><span class="nx">tokenIndice</span><span class="p">.</span><span class="nx">has</span><span class="p">(</span><span class="nx">token</span><span class="p">))</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">tokenIndice</span><span class="p">.</span><span class="nx">set</span><span class="p">(</span><span class="nx">token</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="nx">size</span><span class="p">)</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">indiceToken</span><span class="p">.</span><span class="nx">set</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">size</span><span class="p">,</span> <span class="nx">token</span><span class="p">)</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">size</span><span class="o">++</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kr">public</span> <span class="nx">fitText</span><span class="p">(</span><span class="nx">text</span><span class="o">:</span> <span class="nx">string</span><span class="p">)</span><span class="o">:</span> <span class="k">void</span> <span class="p">{</span>
    <span class="kr">const</span> <span class="nx">tokenList</span> <span class="o">=</span> <span class="p">[...</span><span class="nx">text</span><span class="p">.</span><span class="nx">split</span><span class="p">(</span><span class="sr">/\s+/</span><span class="p">)]</span>

    <span class="k">if</span> <span class="p">(</span><span class="nx">tokenList</span><span class="p">.</span><span class="nx">length</span> <span class="o">&gt;</span> <span class="k">this</span><span class="p">.</span><span class="nx">maxSeqLength</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">maxSeqLength</span> <span class="o">=</span> <span class="nx">tokenList</span><span class="p">.</span><span class="nx">length</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="p">(</span><span class="kr">const</span> <span class="nx">token</span> <span class="k">of</span> <span class="nx">tokenList</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">fitToken</span><span class="p">(</span><span class="nx">token</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kr">public</span> <span class="nx">token</span><span class="p">(</span><span class="nx">indice</span><span class="o">:</span> <span class="nx">number</span><span class="p">)</span><span class="o">:</span> <span class="nx">string</span> <span class="p">{</span>
    <span class="k">return</span> <span class="k">this</span><span class="p">.</span><span class="nx">indiceToken</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="nx">indice</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">string</span>
  <span class="p">}</span>

  <span class="kr">public</span> <span class="nx">indice</span> <span class="p">(</span><span class="nx">token</span><span class="o">:</span> <span class="nx">string</span><span class="p">)</span><span class="o">:</span> <span class="nx">number</span> <span class="p">{</span>
    <span class="k">return</span> <span class="k">this</span><span class="p">.</span><span class="nx">tokenIndice</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="nx">token</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">number</span>
  <span class="p">}</span>

  <span class="kr">public</span> <span class="nx">sequenize</span> <span class="p">(</span>
    <span class="nx">text</span><span class="o">:</span> <span class="nx">string</span><span class="p">,</span>
    <span class="nx">length</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
  <span class="p">)</span><span class="o">:</span> <span class="nx">number</span><span class="p">[]</span> <span class="p">{</span>
    <span class="kr">const</span> <span class="nx">tokenList</span> <span class="o">=</span> <span class="p">[...</span><span class="nx">text</span><span class="p">.</span><span class="nx">split</span><span class="p">(</span><span class="sr">/\s+/</span><span class="p">)]</span>
    <span class="kr">const</span> <span class="nx">indiceList</span> <span class="o">=</span> <span class="nx">tokenList</span><span class="p">.</span><span class="nx">map</span><span class="p">(</span><span class="nx">token</span> <span class="p">=&gt;</span> <span class="k">this</span><span class="p">.</span><span class="nx">indice</span><span class="p">(</span><span class="nx">token</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span><span class="nx">length</span> <span class="o">===</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">indiceList</span><span class="p">.</span><span class="nx">length</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nx">maxSeqLength</span>
      <span class="k">if</span> <span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">maxSeqLength</span> <span class="o">&gt;</span> <span class="nx">tokenList</span><span class="p">.</span><span class="nx">length</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">indiceList</span><span class="p">.</span><span class="nx">fill</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nx">tokenList</span><span class="p">.</span><span class="nx">length</span><span class="p">)</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="nx">indiceList</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>接下來，我們將資料集和 <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> 結合起來，並對資料集進行資料向量化。</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">export</span> <span class="kr">const</span> <span class="nx">START_TOKEN</span> <span class="o">=</span> <span class="s1">&#39;\t&#39;</span>
<span class="kr">export</span> <span class="kr">const</span> <span class="nx">END_TOKEN</span> <span class="o">=</span> <span class="s1">&#39;\n&#39;</span>

<span class="kr">const</span> <span class="nx">voc</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Vocabulary</span><span class="p">()</span>

<span class="nx">voc</span><span class="p">.</span><span class="nx">fitToken</span><span class="p">(</span><span class="nx">START_TOKEN</span><span class="p">)</span>
<span class="nx">voc</span><span class="p">.</span><span class="nx">fitToken</span><span class="p">(</span><span class="nx">END_TOKEN</span><span class="p">)</span>

<span class="nx">await</span> <span class="nx">dataset</span><span class="p">.</span><span class="nx">forEachAsync</span><span class="p">(</span><span class="nx">value</span> <span class="p">=&gt;</span> <span class="p">{</span>
  <span class="nx">voc</span><span class="p">.</span><span class="nx">fitText</span><span class="p">(</span><span class="nx">value</span><span class="p">.</span><span class="nx">input</span><span class="p">)</span>
  <span class="nx">voc</span><span class="p">.</span><span class="nx">fitText</span><span class="p">(</span><span class="nx">value</span><span class="p">.</span><span class="nx">output</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1">// 額外的 START_TOKEN 和 END_TOKEN</span>
<span class="nx">voc</span><span class="p">.</span><span class="nx">maxSeqLength</span> <span class="o">+=</span> <span class="mi">2</span>

<span class="kr">const</span> <span class="nx">seq2seqDataset</span> <span class="o">=</span> <span class="nx">dataset</span>
<span class="p">.</span><span class="nx">map</span><span class="p">(</span><span class="nx">value</span> <span class="p">=&gt;</span> <span class="p">{</span>
  <span class="kr">const</span> <span class="nx">input</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">tensor</span><span class="p">(</span><span class="nx">voc</span><span class="p">.</span><span class="nx">sequenize</span><span class="p">(</span><span class="nx">value</span><span class="p">.</span><span class="nx">input</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

  <span class="kr">const</span> <span class="nx">decoderInputBuf</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">buffer</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R1</span><span class="o">&gt;</span><span class="p">([</span>
    <span class="nx">voc</span><span class="p">.</span><span class="nx">maxSeqLength</span><span class="p">,</span>
  <span class="p">])</span>
  <span class="kr">const</span> <span class="nx">decoderTargetBuf</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">buffer</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R2</span><span class="o">&gt;</span><span class="p">([</span>
    <span class="nx">voc</span><span class="p">.</span><span class="nx">maxSeqLength</span><span class="p">,</span>
    <span class="nx">voc</span><span class="p">.</span><span class="nx">size</span><span class="p">,</span>
  <span class="p">])</span>

  <span class="kr">const</span> <span class="nx">outputIndiceList</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nx">voc</span><span class="p">.</span><span class="nx">indice</span><span class="p">(</span><span class="nx">START_TOKEN</span><span class="p">),</span>
    <span class="p">...</span><span class="nx">voc</span><span class="p">.</span><span class="nx">sequenize</span><span class="p">(</span><span class="nx">value</span><span class="p">.</span><span class="nx">output</span><span class="p">),</span>
    <span class="nx">voc</span><span class="p">.</span><span class="nx">indice</span><span class="p">(</span><span class="nx">END_TOKEN</span><span class="p">),</span>
  <span class="p">]</span>

  <span class="k">for</span> <span class="p">(</span><span class="kr">const</span> <span class="p">[</span><span class="nx">t</span><span class="p">,</span> <span class="nx">indice</span><span class="p">]</span> <span class="k">of</span> <span class="nx">outputIndiceList</span><span class="p">.</span><span class="nx">entries</span><span class="p">())</span> <span class="p">{</span>
    <span class="nx">decoeerInputBuf</span><span class="p">.</span><span class="nx">set</span><span class="p">(</span><span class="nx">indice</span><span class="p">,</span> <span class="nx">t</span><span class="p">)</span>

    <span class="c1">// shift left for target: not including START_OF_SEQ</span>
    <span class="k">if</span> <span class="p">(</span><span class="nx">t</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">decoderTargetBuf</span><span class="p">.</span><span class="nx">set</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nx">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="nx">indice</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kr">const</span> <span class="nx">decoderInput</span> <span class="o">=</span> <span class="nx">decoderInputBuf</span><span class="p">.</span><span class="nx">toTensor</span><span class="p">()</span>
  <span class="kr">const</span> <span class="nx">decoderTarget</span> <span class="o">=</span> <span class="nx">decoderTargetBuf</span><span class="p">.</span><span class="nx">toTensor</span><span class="p">()</span>

  <span class="kr">const</span> <span class="nx">xs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nx">seq2seqInputs</span><span class="o">:</span> <span class="nx">inputTensor</span><span class="p">,</span>
    <span class="nx">seq2seqDecoderInputs</span><span class="o">:</span> <span class="nx">decoderInput</span><span class="p">,</span>
  <span class="p">}</span>
  <span class="kr">const</span> <span class="nx">ys</span> <span class="o">=</span> <span class="nx">decoderTarget</span>

  <span class="k">return</span> <span class="p">{</span><span class="nx">xs</span><span class="p">,</span> <span class="nx">ys</span><span class="p">}</span>
<span class="p">})</span>
</pre></div>
</div>
<p>接下來進行模型的實現。我們先建立 Seq2Seq 模型所需的所有 Layers，具體實現如下：</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="cm">/**</span>
<span class="cm"> * Encoder Layers</span>
<span class="cm"> */</span>
<span class="kr">const</span> <span class="nx">encoderEmbeddingLayer</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">embedding</span><span class="p">({</span>
  <span class="nx">inputDim</span><span class="o">:</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">size</span><span class="p">,</span>
  <span class="nx">outputDim</span><span class="o">:</span> <span class="nx">latentDim</span><span class="p">,</span>
<span class="p">})</span>

<span class="kr">const</span> <span class="nx">encoderRnnLayer</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">gru</span><span class="p">({</span>
  <span class="nx">units</span><span class="o">:</span> <span class="nx">latentDim</span><span class="p">,</span>
  <span class="nx">returnState</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">})</span>

<span class="cm">/**</span>
<span class="cm"> * Decoder Layers</span>
<span class="cm"> */</span>
<span class="kr">const</span> <span class="nx">decoderEmbeddingLayer</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">embedding</span><span class="p">({</span>
  <span class="nx">inputDim</span><span class="o">:</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">size</span><span class="p">,</span>
  <span class="nx">outputDim</span><span class="o">:</span> <span class="nx">latentDim</span><span class="p">,</span>
<span class="p">})</span>

<span class="kr">const</span> <span class="nx">decoderRnnLayer</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">gru</span><span class="p">({</span>
  <span class="nx">units</span><span class="o">:</span> <span class="nx">latentDim</span><span class="p">,</span>
  <span class="nx">returnSequences</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="nx">returnState</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">})</span>

<span class="kr">const</span> <span class="nx">decoderDenseLayer</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">dense</span><span class="p">({</span>
    <span class="nx">units</span><span class="o">:</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">size</span><span class="p">,</span>
    <span class="nx">activation</span><span class="o">:</span> <span class="s1">&#39;softmax&#39;</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
<p>然後，由這些 Layers ，來建立我們的 Seq2Seq 模型。需要註意的是我們需要共用這些 Layers 建立三個不同的模型，分別是：</p>
<ul class="simple">
<li><p>用來訓練的完整 Seq2Seq 模型： <code class="docutils literal notranslate"><span class="pre">seq2seqModel</span></code></p></li>
<li><p>用來對序列進行編碼的 Encoder 模型： <code class="docutils literal notranslate"><span class="pre">encoderModel</span></code></p></li>
<li><p>用來對序列進行解碼的 Decoder 模型： <code class="docutils literal notranslate"><span class="pre">decoderModel</span></code></p></li>
</ul>
<p>請註意這三個模型中，只有第一個模型  <code class="docutils literal notranslate"><span class="pre">seq2seqModel</span></code>  是用來訓練參數所需要的，所以訓練的的時候使用這個模型。而另外的兩個模型 <code class="docutils literal notranslate"><span class="pre">encoderModel</span></code> 和 <code class="docutils literal notranslate"><span class="pre">decoderModel</span></code> ，使我們用來預測的時候需要使用的。這三個模型共用所有的 Layers 參數。</p>
<p><code class="docutils literal notranslate"><span class="pre">seq2seqModel</span></code> 模型的輸入包含兩個，一個是 Encoder 的輸入，另外一個是 Decoder 的輸入。模型的輸出是我們資料集的輸出。</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">const</span> <span class="nx">inputs</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">input</span><span class="p">({</span>
  <span class="nx">shape</span><span class="o">:</span> <span class="p">[</span><span class="kc">null</span><span class="p">],</span>
  <span class="nx">name</span><span class="o">:</span> <span class="s1">&#39;seq2seqInputs&#39;</span><span class="p">,</span>
<span class="p">})</span>

<span class="kr">const</span> <span class="nx">encoderEmbedding</span> <span class="o">=</span> <span class="nx">encoderEmbeddingLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">inputs</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R3</span><span class="o">&gt;</span>

<span class="kr">const</span> <span class="p">[,</span> <span class="nx">encoderState</span><span class="p">]</span> <span class="o">=</span> <span class="nx">encoderRnnLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">encoderEmbedding</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span><span class="p">[]</span>

<span class="kr">const</span> <span class="nx">decoderInputs</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">input</span><span class="p">({</span>
  <span class="nx">shape</span><span class="o">:</span> <span class="p">[</span><span class="nx">voc</span><span class="p">.</span><span class="nx">maxSeqLength</span><span class="p">],</span>
  <span class="nx">name</span><span class="o">:</span> <span class="s1">&#39;seq2seqDecoderInputs&#39;</span><span class="p">,</span>
<span class="p">})</span>

<span class="kr">const</span> <span class="nx">decoderEmbedding</span> <span class="o">=</span> <span class="nx">decoderEmbeddingLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">decoderInputs</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span>

<span class="kr">const</span> <span class="p">[</span><span class="nx">decoderOutputs</span><span class="p">,]</span> <span class="o">=</span> <span class="nx">decoderRnnLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span>
  <span class="p">[</span><span class="nx">decoderEmbedding</span><span class="p">,</span> <span class="nx">encoderState</span><span class="p">],</span>
  <span class="p">{</span>
    <span class="nx">returnSequences</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nx">returnState</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="p">},</span>
<span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span><span class="p">[]</span>

<span class="kr">const</span> <span class="nx">decoderTargets</span> <span class="o">=</span> <span class="nx">decoderDenseLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">decoderOutputs</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span>

<span class="kr">const</span> <span class="nx">seq2seqModel</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">model</span><span class="p">({</span>
  <span class="nx">inputs</span><span class="o">:</span> <span class="p">[</span><span class="nx">inputs</span><span class="p">,</span> <span class="nx">decoderInputs</span><span class="p">],</span>
  <span class="nx">outputs</span><span class="o">:</span> <span class="nx">decoderTargets</span><span class="p">,</span>
  <span class="nx">name</span><span class="o">:</span> <span class="s1">&#39;seq2seqModel&#39;</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
<p>用來訓練的 <code class="docutils literal notranslate"><span class="pre">seq2seqModel</span></code> 模型建立完畢後，即可基於模型的 <code class="docutils literal notranslate"><span class="pre">fitDataset</span></code> 函數進行訓練：</p>
<p>訓練大約需要幾個小時的時間，才能達到比較好的效果。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">20</span>
<span class="n">eta</span><span class="o">=</span><span class="mf">0.0</span> <span class="o">&gt;</span>
<span class="mi">90436</span><span class="n">ms</span> <span class="mi">576025</span><span class="n">us</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="o">=</span><span class="mf">4.82</span>
<span class="n">Epoch</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">20</span>
<span class="n">eta</span><span class="o">=</span><span class="mf">0.0</span> <span class="o">&gt;</span>
<span class="mi">85229</span><span class="n">ms</span> <span class="mi">542858</span><span class="n">us</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="o">=</span><span class="mf">4.07</span>
<span class="n">Epoch</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">20</span>
<span class="n">eta</span><span class="o">=</span><span class="mf">0.0</span> <span class="o">&gt;</span>
<span class="mi">81913</span><span class="n">ms</span> <span class="mi">521742</span><span class="n">us</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="o">=</span><span class="mf">3.77</span>
<span class="n">Epoch</span> <span class="mi">4</span> <span class="o">/</span> <span class="mi">20</span>
<span class="n">eta</span><span class="o">=</span><span class="mf">0.0</span> <span class="o">-</span> <span class="n">loss</span><span class="o">=</span><span class="mf">3.52</span>
<span class="o">...</span>
</pre></div>
</div>
<p>然後，為了能夠讓我們使用訓練好的模型，我們還需要基於已經訓練好的模型 Layer 參數，構建獨立的 <code class="docutils literal notranslate"><span class="pre">encoderModel</span></code> 和 <code class="docutils literal notranslate"><span class="pre">decoderModel</span></code> 。</p>
<p>Encoder子模型輸入 <code class="docutils literal notranslate"><span class="pre">numBatch</span></code> 個由編碼後單詞和字元組成的，長為 <code class="docutils literal notranslate"><span class="pre">maxLength</span></code> 的序列，輸入張量形狀為 <code class="docutils literal notranslate"><span class="pre">[numBatch,</span> <span class="pre">maxLength]</span></code> ，輸出與這個序列對應的上下文狀態張量。</p>
<p><code class="docutils literal notranslate"><span class="pre">encoderModel</span></code> 的代碼實現如下：</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">const</span> <span class="nx">encoderInputs</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">input</span><span class="p">({</span>
  <span class="nx">shape</span><span class="o">:</span> <span class="p">[</span><span class="kc">null</span><span class="p">],</span>
  <span class="nx">name</span><span class="o">:</span> <span class="s1">&#39;encoderInputs&#39;</span><span class="p">,</span>
<span class="p">})</span>
<span class="kr">const</span> <span class="nx">encoderEmbedding</span> <span class="o">=</span> <span class="nx">encoderEmbeddingLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">encoderInputs</span><span class="p">)</span>
<span class="kr">const</span> <span class="p">[,</span> <span class="nx">encoderState</span><span class="p">]</span> <span class="o">=</span> <span class="nx">encoderRnnLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">encoderEmbedding</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span><span class="p">[]</span>

<span class="kr">const</span> <span class="nx">encoderModel</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">model</span><span class="p">({</span>
  <span class="nx">inputs</span><span class="o">:</span> <span class="nx">encoderInputs</span><span class="p">,</span>
  <span class="nx">outputs</span><span class="o">:</span> <span class="nx">encoderState</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">deocoderModel</span></code> 的輸入有兩個，分別是 t 時間的 token indice，和對應的解碼器 <code class="docutils literal notranslate"><span class="pre">state</span></code>；輸出也有兩個，分別是 t+1 時間的 token 的 voc 分佈機率，和對應的解碼器 <code class="docutils literal notranslate"><span class="pre">state</span></code> ：</p>
<p><code class="docutils literal notranslate"><span class="pre">decoderModel</span></code> 子模型具體實現如下：</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">const</span> <span class="nx">decoderInput</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">input</span><span class="p">({</span>
  <span class="nx">shape</span><span class="o">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
  <span class="nx">name</span><span class="o">:</span> <span class="s1">&#39;decoderInputs&#39;</span><span class="p">,</span>
<span class="p">})</span>
<span class="kr">const</span> <span class="nx">decoderStateInput</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">layers</span><span class="p">.</span><span class="nx">input</span><span class="p">({</span>
  <span class="nx">shape</span><span class="o">:</span> <span class="p">[</span><span class="nx">latentDim</span><span class="p">],</span>
  <span class="nx">name</span><span class="o">:</span> <span class="s1">&#39;decoderState&#39;</span><span class="p">,</span>
<span class="p">})</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span>

<span class="kr">const</span> <span class="nx">decoderEmbedding</span> <span class="o">=</span> <span class="nx">decoderEmbeddingLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">decoderInput</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span>

<span class="kr">const</span> <span class="p">[</span><span class="nx">decoderOutputs</span><span class="p">,</span> <span class="nx">decoderStateOutput</span><span class="p">]</span> <span class="o">=</span> <span class="nx">decoderRnnLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span>
  <span class="p">[</span><span class="nx">decoderEmbedding</span><span class="p">,</span> <span class="nx">decoderStateInput</span><span class="p">],</span>
  <span class="p">{</span>
    <span class="nx">returnState</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="p">},</span>
<span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span><span class="p">[]</span>
<span class="kr">const</span> <span class="nx">decoderDenseOutputs</span> <span class="o">=</span> <span class="nx">decoderDenseLayer</span><span class="p">.</span><span class="nx">apply</span><span class="p">(</span><span class="nx">decoderOutputs</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">SymbolicTensor</span>

<span class="kr">const</span> <span class="nx">decoderModel</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">model</span><span class="p">({</span>
  <span class="nx">inputs</span><span class="o">:</span> <span class="p">[</span><span class="nx">decoderInput</span><span class="p">,</span> <span class="nx">decoderStateInput</span><span class="p">],</span>
  <span class="nx">outputs</span><span class="o">:</span> <span class="p">[</span><span class="nx">decoderDenseOutputs</span><span class="p">,</span> <span class="nx">decoderStateOutput</span><span class="p">],</span>
<span class="p">})</span>
</pre></div>
</div>
<p>最後，我們需要一個用來對話的程式。我們建立一個專門用來接收一句話輸入，然後通過我們的模型預測，得到序列輸出的函數 <code class="docutils literal notranslate"><span class="pre">seq2seqDecoder()</span></code> ：</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">export</span> <span class="nx">async</span> <span class="kd">function</span> <span class="nx">seq2seqDecoder</span> <span class="p">(</span>
  <span class="nx">input</span><span class="o">:</span> <span class="nx">string</span><span class="p">,</span>
  <span class="nx">encoderModel</span><span class="o">:</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">LayersModel</span><span class="p">,</span>
  <span class="nx">decoderModel</span><span class="o">:</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">LayersModel</span><span class="p">,</span>
  <span class="nx">voc</span><span class="o">:</span> <span class="nx">Vocabulary</span><span class="p">,</span>
<span class="p">)</span><span class="o">:</span> <span class="nb">Promise</span><span class="o">&lt;</span><span class="nx">string</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="kr">const</span> <span class="nx">inputSeq</span> <span class="o">=</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">sequenize</span><span class="p">(</span><span class="nx">input</span><span class="p">)</span>
  <span class="kr">const</span> <span class="nx">inputTensor</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">tensor</span><span class="p">(</span><span class="nx">inputSeq</span><span class="p">)</span>

  <span class="kr">const</span> <span class="nx">batchedInput</span> <span class="o">=</span> <span class="nx">inputTensor</span><span class="p">.</span><span class="nx">expandDims</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="kd">let</span> <span class="nx">state</span> <span class="o">=</span> <span class="nx">encoderModel</span><span class="p">.</span><span class="nx">predict</span><span class="p">(</span><span class="nx">batchedInput</span><span class="p">)</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R2</span><span class="o">&gt;</span>

  <span class="kd">let</span> <span class="nx">tokenIndice</span> <span class="o">=</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">indice</span><span class="p">(</span><span class="nx">START_TOKEN</span><span class="p">)</span>

  <span class="kd">let</span> <span class="nx">decoderOutputs</span><span class="o">:</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R3</span><span class="o">&gt;</span>
  <span class="kd">let</span> <span class="nx">decodedToken</span><span class="o">:</span> <span class="nx">string</span>
  <span class="kd">let</span> <span class="nx">decodedTokenList</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">do</span> <span class="p">{</span>
    <span class="kr">const</span> <span class="nx">decoderInputs</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">tensor</span><span class="p">(</span><span class="nx">tokenIndice</span><span class="p">).</span><span class="nx">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="nx">as</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R2</span><span class="o">&gt;</span>

    <span class="p">;[</span><span class="nx">decoderOutputs</span><span class="p">,</span> <span class="nx">state</span><span class="p">]</span> <span class="o">=</span> <span class="nx">decoderModel</span><span class="p">.</span><span class="nx">predict</span><span class="p">([</span>
      <span class="nx">decoderInputs</span><span class="p">,</span>
      <span class="nx">state</span><span class="p">,</span>
    <span class="p">])</span> <span class="nx">as</span> <span class="p">[</span>
      <span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R3</span><span class="o">&gt;</span><span class="p">,</span>
      <span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="o">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Rank</span><span class="p">.</span><span class="nx">R2</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="kd">let</span> <span class="nx">decodedIndice</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">decoderOutputs</span>
                                <span class="p">.</span><span class="nx">squeeze</span><span class="p">()</span>
                                <span class="p">.</span><span class="nx">argMax</span><span class="p">()</span>
                                <span class="p">.</span><span class="nx">array</span><span class="p">()</span> <span class="nx">as</span> <span class="nx">number</span>

    <span class="k">if</span> <span class="p">(</span><span class="nx">decodedIndice</span> <span class="o">===</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// 0 for padding, should be treated as END</span>
      <span class="nx">decodedToken</span> <span class="o">=</span> <span class="nx">END_TOKEN</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="nx">decodedToken</span> <span class="o">=</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">token</span><span class="p">(</span><span class="nx">decodedIndice</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="p">(</span><span class="nx">decodedToken</span> <span class="o">===</span> <span class="nx">END_TOKEN</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">break</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="nx">decodedTokenList</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">decodedToken</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="c1">// save decoded data for next time step</span>
    <span class="nx">tokenIndice</span> <span class="o">=</span> <span class="nx">decodedIndice</span>

  <span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="nx">decodedTokenList</span><span class="p">.</span><span class="nx">length</span> <span class="o">&lt;</span> <span class="nx">voc</span><span class="p">.</span><span class="nx">maxSeqLength</span><span class="p">)</span>

  <span class="k">return</span> <span class="nx">decodedTokenList</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
<p>最後，我們就可以用我們訓練好的Seq2Seq模型，實現我們的 ChitChat 聊天功能了：</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">const</span> <span class="nx">input</span> <span class="o">=</span> <span class="s1">&#39;how are you ?&#39;</span>

<span class="kr">const</span> <span class="nx">decodedOutput</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">seq2seqDecoder</span><span class="p">(</span>
  <span class="nx">input</span><span class="p">,</span>
  <span class="nx">encoderModel</span><span class="p">,</span>
  <span class="nx">decoderModel</span><span class="p">,</span>
  <span class="nx">inputVoc</span><span class="p">,</span>
  <span class="nx">outputVoc</span><span class="p">,</span>
<span class="p">)</span>

<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="sb">`Input sentence: &quot;</span><span class="si">${</span><span class="nx">input</span><span class="si">}</span><span class="sb">&quot;`</span><span class="p">)</span>
<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="sb">`Decoded sentence: &quot;</span><span class="si">${</span><span class="nx">decodedOutput</span><span class="si">}</span><span class="sb">&quot;`</span><span class="p">)</span>
</pre></div>
</div>
<p>模型每次的訓練，得到的結果都會不盡相同。作者的某一次輸出的內容是下面這樣的：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input sentence： &quot;how are you ?&quot;
Decoded setence: &quot;good .&quot;
</pre></div>
</div>
<p>註：本章節中的 JavaScript 版 ChitChat 完整程式碼，使用說明，和訓練好的模型文件及參數，都可以在作者的 GitHub 上找到。地址： <a class="reference external" href="https://github.com/huan/tensorflow-handbook-javascript">https://github.com/huan/tensorflow-handbook-javascript</a></p>
</div>
<div class="section" id="tensorflow-swift">
<h2>TensorFlow Swift 閒聊機器人<a class="headerlink" href="#tensorflow-swift" title="永久链接至标题">¶</a></h2>
<p>如果時間來得及，完成 Seq2Seq 模型。</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2021, Xihan Li (snowkylin)

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

  <p><a href="https://beian.miit.gov.cn/" target="_blank">沪ICP备13038357号-18</a ></p> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-40509304-12', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>